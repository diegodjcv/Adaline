{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> InvestigaciÃ³n - Practica 3 </center>\n",
    "\n",
    "### Inteligencia Artificial II\n",
    "\n",
    "**Nombre:** Diego Cabrera\n",
    "<hr>\n",
    "\n",
    "### **Red Adeline**\n",
    "\n",
    "\n",
    "\n",
    "* *Describir la arquitectura de la red y su regla de aprendizaje.*\n",
    "\n",
    "<DIV ALIGN=\"justify\">La arquitectura de Adaline (Adaptive Linear Neuron) fue creada por Bernard Widrow en 1959. Utiliza un dispositivo lÃ³gico que realiza una suma lineal de las entradas y genera una funciÃ³n umbral para el resultado de dicha suma. La topologÃ­a de la red ADALINE es similar a la del perceptrÃ³n sÃ³lo que en este caso la funciÃ³n de salida de las neuronas es lineal. Dado que las seÃ±ales de entrada pueden ser continuas, la red ADALINE es un dispositivo de entrada/salida analÃ³gica (continua) a diferencia del perceptrÃ³n que de acuerdo a lo dicho anteriormente es un dispositivo entrada/salida digital (binaria). La operaciÃ³n de una red ADALINE con n neuronas de entrada y m neuronas de salidas puede ser resumida de la siguiente manera: </DIV>\n",
    "\n",
    "<img src=\"formula1.png\">\n",
    "\n",
    "<DIV ALIGN=\"justify\">Sin embargo, la principal diferencia entre la red ADALINE y el perceptrÃ³n consiste en la regla de aprendizaje que utilizan. En el caso de la red ADALINE implementa como mÃ©todo de aprendizaje la regla de Widrow-Hoff, tambiÃ©n conocida como regla LMS (Least Mean Squares, mÃ­nimos cuadrados), que realiza una actualizaciÃ³n continua de los pesos sinÃ¡pticos de acuerdo a la contribuciÃ³n de cada neurona sobre el error total de la red.</DIV>\n",
    "\n",
    "* **Estructura Adaline**\n",
    "\n",
    "<DIV ALIGN=\"justify\"> La unidad procesadora representada por un cÃ­rculo con el sÃ­mbolo sumatorio implementa una funciÃ³n umbral. Las conexiones de cada una de las entradas tienen asociadas un valor de ponderaciÃ³n llamado tambiÃ©n peso wi. \n",
    "    </DIV>\n",
    "\n",
    "<DIV ALIG=\"justify\">El Adaline es Lineal porque la salida es una funciÃ³n lineal sencilla de los valores de la entrada. Es una Neurona tan solo en el sentido (muy limitado) del PE. TambiÃ©n se podrÃ­a decir que el Adaline es un Elemento Lineal, evitando por completo la definiciÃ³n como Neurona.Si se combinan varios adalines se obtiene la configuraciÃ³n denominada Madaline</DIV>\n",
    "\n",
    "<DIV ALIGN=\"justify\">La estructura general de la red tipo Adaline puede visualizarse en la siguiente figura: </DIV>\n",
    "\n",
    "<img src=\"formula2.png\">\n",
    "\n",
    "\n",
    "\n",
    "* Perceptron Multicapa\n",
    "\n",
    "<DIV ALIGN=\"justify\">El perceptrÃ³n multicapa es una extensiÃ³n del perceptrÃ³n simple. La topologÃ­a de un perceptrÃ³n multicapa esta definida por un conjunto de capas ocultas, una capa de entrada y una de salida. No existen restricciones sobre la funciÃ³n de activaciÃ³n aunque en general se suelen utilizar funciones sigmoideas. </DIV>\n",
    "\n",
    "\n",
    "* Algoritmo de aprendizaje\n",
    "<DIV ALIGN=\"justify\"> Primero se realiza el cÃ¡lculo de la suma ponderada de las N entradas:</DIV>\n",
    "\n",
    "<img src=\"formula2.png\"> \n",
    "\n",
    "<br>\n",
    "\n",
    "<DIV ALIGN=\"justify\"> El orden de operaciones de ADALINE es el siguiente:\n",
    "\n",
    "1. Presentar un patrÃ³n de entrada ğ‘‹ = (ğ‘¥1, ğ‘¥2, ğ‘¥3 â€¦ ğ‘¥ğ‘)\n",
    "2. Calcular la salida y = w1x1 + w2x2 + w3x3 â€¦ wğ‘xğ‘\n",
    "3. Comparar con la salida esperada E= (ğ‘‘ âˆ’ y)\n",
    "4. Calcular la actualizaciÃ³n pesos y el umbral.\n",
    "âˆ†ğ‘ğ‘¤ğ‘— = ğ›¾ Â· âˆ†ğ‘ Â· ğ‘¥ğ‘—\n",
    "5. Modificar los pesos y el umbral\n",
    "ğ‘¤ğ‘—(ğ‘¡ + 1) = ğ‘¤ğ‘—(ğ‘¡) + âˆ†ğ‘ğ‘¤ğ‘—\n",
    " ğœƒ(ğ‘¡ + 1) = ğœƒ(ğ‘¡) + âˆ†ğ‘ğœƒ\n",
    "6. Repetir de 1 a 5 hasta acabar con todos los patrones de entrada\n",
    "= Completar un ciclo de aprendizaje\n",
    "7. Realizar ciclos de aprendizaje (Repetir de 1 a 6) hasta alcanzar el\n",
    "criterio de parada. </DIV>\n",
    "    \n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "<img src=\"ejercicio.png\" > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=  [[0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "W=  [0.78 0.66]\n",
      "ALFA=  0.8\n",
      "NUM: 0 NUEVOS PESOS: 2.01   1.18\n",
      "NUM: 1 NUEVOS PESOS: 1.97   1.01\n",
      "NUM: 2 NUEVOS PESOS: 2.0   1.0\n",
      "NUM: 3 NUEVOS PESOS: 2.0   1.0\n",
      "NUM: 4 NUEVOS PESOS: 2.0   1.0\n",
      "NUM: 5 NUEVOS PESOS: 2.0   1.0\n",
      "NUM: 6 NUEVOS PESOS: 2.0   1.0\n",
      "NUM: 7 NUEVOS PESOS: 2.0   1.0\n",
      "NUM: 8 NUEVOS PESOS: 2.0   1.0\n",
      "NUM: 9 NUEVOS PESOS: 2.0   1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "alfa = 0.8\n",
    "    \n",
    "INPUTS = np.array([[0,1],\n",
    "                   [1,0],\n",
    "                   [1,1]\n",
    "                   ])\n",
    "        \n",
    "OUTPUTS = np.array([[1,2,3]]).T\n",
    "\n",
    "WEIGHTS = np.array([0.78,0.66])\n",
    "\n",
    "print(\"X= \",INPUTS)\n",
    "print(\"W= \",WEIGHTS)\n",
    "print(\"ALFA= \",alfa)\n",
    "\n",
    "\n",
    "errors=[]\n",
    "w= []\n",
    "# Training loop\n",
    "\n",
    "for i in range(10):\n",
    "    for fila in range(3):\n",
    "        #print(\"PESOS:\",WEIGHTS[0],\" \",WEIGHTS[1],\" \",WEIGHTS[2])\n",
    "        y=(INPUTS[fila][0]*WEIGHTS[0])+(INPUTS[fila][1]*WEIGHTS[1])\n",
    "        #print(\"VALOR:\",INPUTS[fila][0],\"VALOR:\",INPUTS[fila][1])\n",
    "        #print(\"y=\",y)\n",
    "\n",
    "        error = OUTPUTS[fila]-y\n",
    "        #print(\"ERROR\",error)\n",
    "\n",
    "        WEIGHTS[0]=WEIGHTS[0]+(alfa*error*INPUTS[fila][0])\n",
    "        WEIGHTS[1]=WEIGHTS[1]+(alfa*error*INPUTS[fila][1])\n",
    "        #print(\"NUEVOS PESOS:\",WEIGHTS[0],\" \",WEIGHTS[1])\n",
    "        #print(\"\\n\")\n",
    "    print(\"NUM:\",i,\"NUEVOS PESOS:\",round(WEIGHTS[0],2),\" \",round(WEIGHTS[1],2))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Referencias**\n",
    "<br>\n",
    "\n",
    "**[1]** Britos, M. I. P. (2005). *Entrenamiento de redes neuronales basado en algoritmos evolutivos* (Doctoral dissertation, UNIVERSIDAD DE BUENOS AIRES).\n",
    "\n",
    "**[2]** Olabe, X. B. (1998). *Redes neuronales artificiales y sus aplicaciones. Publicaciones de la Escuela de Ingenieros.*\n",
    "\n",
    "**[3]** Tanco, F. (2003). *IntroducciÃ³n a las redes neuronales artificiales. Grupo de Inteligencia Artificial.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7-simulacion",
   "language": "python",
   "name": "simulacion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
